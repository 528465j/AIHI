{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ae0a6e-85f3-4b7f-bb44-f3c95a6fbc84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bcb349-95d5-4dcc-a941-f226b9efdd3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38300ef7-0978-4e7c-a1fe-aa37639257c3",
   "metadata": {},
   "source": [
    "<h1 id=\"setup\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Setup</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f741af-97f0-4b7c-9fe3-0fcf19785c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3146fce9-d5b0-4eea-a96f-aac64d740707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-fid\n",
      "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from pytorch-fid) (1.26.4)\n",
      "Requirement already satisfied: pillow in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from pytorch-fid) (10.2.0)\n",
      "Requirement already satisfied: scipy in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from pytorch-fid) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.0.1 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from pytorch-fid) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from pytorch-fid) (0.18.0)\n",
      "Requirement already satisfied: filelock in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (4.9.0)\n",
      "Requirement already satisfied: sympy in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (1.12)\n",
      "Requirement already satisfied: networkx in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.1)\n",
      "Requirement already satisfied: jinja2 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from torch>=1.0.1->pytorch-fid) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from jinja2->torch>=1.0.1->pytorch-fid) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from sympy->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
      "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pytorch-fid\n",
      "Successfully installed pytorch-fid-0.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f37f4e-69f2-47ac-989c-478439e26e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paramiko\n",
      "  Downloading paramiko-3.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting bcrypt>=3.2 (from paramiko)\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting cryptography>=3.3 (from paramiko)\n",
      "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pynacl>=1.5 (from paramiko)\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from cryptography>=3.3->paramiko) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /scratch/xw97/jj7317/miniconda3/envs/new-env-temp/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.21)\n",
      "Downloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bcrypt, pynacl, cryptography, paramiko\n",
      "Successfully installed bcrypt-4.1.3 cryptography-42.0.8 paramiko-3.4.0 pynacl-1.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e377df0d-70b9-4d17-a25c-6d76bb7f270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 2.3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e9b86-a4fb-4782-9817-817e640e5b45",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b377d4-a948-473d-91d8-eba0f92462f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "# Setup device-agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7903d-21ce-4317-8d32-54a37a6d2008",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d1db3-b6ea-466d-a619-a6237b374516",
   "metadata": {},
   "source": [
    "<h1 id=\"initiating-image-loading\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Initiating Image Loading</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d46585-1330-4e0d-bdd5-7eec87668b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df = pd.read_csv('path/to/list_attr_celeba.csv')\n",
    "bbox_df = pd.read_csv('path/to/list_bbox_celeba.csv')\n",
    "eval_df = pd.read_csv('path/to/list_eval_partition.csv')\n",
    "landmarks_df = pd.read_csv('path/to/list_landmarks_align_celeba.csv')\n",
    "\n",
    "# Merge dataframes on the image_id\n",
    "df = attr_df.merge(bbox_df, on='image_id')\n",
    "df = df.merge(eval_df, on='image_id')\n",
    "df = df.merge(landmarks_df, on='image_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaff809-bd31-4ab3-af82-392b4de3e5d8",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecb181-5ab6-462f-886b-c646645c9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3ca34-c2cc-43ed-b0db-e8eea114511a",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d319c-f4c7-47e0-991b-89f7de821acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Custom Dataset class\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.dataframe.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Get attributes\n",
    "        labels = self.dataframe.iloc[idx, 1:41].values.astype(float)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e6376-4cd6-4f09-956a-c24b786e192e",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8176e-0e96-4a9b-80e5-7094330f8112",
   "metadata": {},
   "source": [
    "<h1 id=\"Visualizing\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Visualizing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2338e5-44d2-4b2d-899f-a07bc3bdfe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to visualize some images\n",
    "def visualize_samples(dataset, num_samples=5):\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(15, 15))\n",
    "    for i in range(num_samples):\n",
    "        idx = np.random.randint(0, len(dataset))\n",
    "        img, labels = dataset[idx]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title(f'Labels: {labels.numpy()}')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee50fa-cd67-4fb6-a1bb-a2b4fc29506f",
   "metadata": {},
   "source": [
    "<h1 id=\"Model Setup & Development\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Model Setup & Development</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3aa72-cd74-4c24-a7ba-540789884ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "img_dir = 'path/to/img_align_celeba'\n",
    "dataset = CelebADataset(df, img_dir, transform=transformations)\n",
    "\n",
    "# Split the dataset\n",
    "train_df = df[df['partition'] == 0]\n",
    "val_df = df[df['partition'] == 1]\n",
    "test_df = df[df['partition'] == 2]\n",
    "\n",
    "train_dataset = CelebADataset(train_df, img_dir, transform=transformations)\n",
    "val_dataset = CelebADataset(val_df, img_dir, transform=transformations)\n",
    "test_dataset = CelebADataset(test_df, img_dir, transform=transformations)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Check the number of samples in each set\n",
    "print(f'Training set size: {len(train_dataset)}')\n",
    "print(f'Validation set size: {len(val_dataset)}')\n",
    "print(f'Test set size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c664f-cfe7-4f39-bb01-425240d5b680",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2cb4f-dde6-4840-a72a-fcdef338db0e",
   "metadata": {},
   "source": [
    "<div style=\"color:#5C5B5B; border-right: 3px solid #5C5B5B; text-align: right; padding: 0px 7px; font-size: 1.17em; font-weight: bold;\">Creating Generator & Discriminator</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711cc10-a946-4090-a345-52d21e5cfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 128, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)\n",
    "\n",
    "# Initialize models\n",
    "noise_dim = 100\n",
    "generator = Generator(noise_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4c1e5-fb26-48a1-af5a-249911c222bb",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27369cdf-e7da-4580-830e-ea13cbf327fd",
   "metadata": {},
   "source": [
    "<div style=\"color:#5C5B5B; border-right: 3px solid #5C5B5B; text-align: right; padding: 0px 7px; font-size: 1.17em; font-weight: normal;\"><strong>Optimizers for both</strong> (Generator & Discriminator) and <strong>Gradient penalty function</strong> (for WGAN-GP)</div>\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08695282-4c99-4f41-b74a-87edae858030",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Gradient penalty function for WGAN-GP\n",
    "def gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    alpha = torch.randn(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    fake = torch.ones(d_interpolates.size(), requires_grad=False, device=device)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4234654-788c-402f-8c97-262e84f75454",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb353c27-18ea-4905-b271-9029e12639bb",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c7f82-d52a-40c5-94f1-f8bc15371644",
   "metadata": {},
   "source": [
    "<h1 id=\"Training and Optimization\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Training and Optimization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6188c86-611b-4ce5-81d0-ba9f5a8c29de",
   "metadata": {},
   "source": [
    "<span style=\"color:#5C5B5B; font-size:1.17em; font-style:italic; border-top:1px solid #5C5B5B; display:block; padding: 0px 5px;\">Explanation:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c778dd3-dd34-4e45-9184-52b1985519f1",
   "metadata": {},
   "source": [
    "<h1 id=\"Evaluation\" align=\"center\" style=\"color:white; background-color:#801A9A; padding:10px; border-bottom: 3px solid #460E54;\">Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d23f2d-97a2-4417-831c-70de5d2f5cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
